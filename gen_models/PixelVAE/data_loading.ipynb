{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.modules['theano'] = None\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import imageio\n",
    "from imageio import imwrite\n",
    "from scipy.misc import imsave, imread\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.sampling_loop\n",
    "import tflib.ops.kl_unit_gaussian\n",
    "import tflib.ops.kl_gaussian_gaussian\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.embedding\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "from fuel.schemes import ShuffledScheme, SequentialScheme\n",
    "from fuel.streams import DataStream\n",
    "# from fuel.transformers.image import RandomFixedSizeCrop\n",
    "\n",
    "PATH = '/Users/wildflowerlyi/Desktop/Image_Samples/cifar10.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new = x_train.transpose(0,3,1,2)\n",
    "x_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_grid_vis(X, nh, nw, savepath):\n",
    "    # from github.com/Newmu\n",
    "    X = X.transpose(0,2,3,1)\n",
    "    h, w = X[0].shape[:2]\n",
    "    img = np.zeros((h*nh, w*nw, 3))\n",
    "    for n, x in enumerate(X):\n",
    "        j = n/nw\n",
    "        i = n%nw\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = x\n",
    "    imsave(savepath,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n",
      "(1, 3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3, 32, 32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train_array = np.array(x_train_new)\n",
    "image = x_train_new[1,:]\n",
    "print(image.shape)\n",
    "image_array = image.reshape(-1,3,32,32)\n",
    "print(image_array.shape)\n",
    "x_array = np.array(image_array)\n",
    "x_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "color_grid_vis(image_array,1,1,'/Users/wildflowerlyi/Desktop/scale.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_stream(stream, bs):\n",
    "    def new_stream():\n",
    "      result = np.empty((bs, 32, 32, 3), dtype='int32')\n",
    "      for (imb,) in stream.get_epoch_iterator():\n",
    "        for i, img in enumerate(imb):\n",
    "          result[i] =  img[:32, :32, :]                \n",
    "        yield (result.transpose(0,3,1,2),)\n",
    "    return new_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size=128): #LEILAEDIT: took out downsampling, changed validation data to CIFAR test set, changed tr_data in line 53 to val_data\n",
    "    \n",
    "    tr_data = H5PYDataset(PATH, which_sets=('train',))\n",
    "    val_data = H5PYDataset(PATH, which_sets=('test',))\n",
    "\n",
    "    ntrain = tr_data.num_examples\n",
    "    nval = val_data.num_examples\n",
    "\n",
    "    print \"ntrain {}, nval {}\".format(ntrain, nval)\n",
    "\n",
    "    tr_scheme = ShuffledScheme(examples=ntrain, batch_size=batch_size)\n",
    "    tr_stream = DataStream(tr_data, iteration_scheme=tr_scheme)\n",
    "\n",
    "    # te_scheme = SequentialScheme(examples=ntest, batch_size=batch_size)\n",
    "    # te_stream = DataStream(te_data, iteration_scheme=te_scheme)\n",
    "\n",
    "    val_scheme = SequentialScheme(examples=nval, batch_size=batch_size)\n",
    "    val_stream = DataStream(val_data, iteration_scheme=val_scheme)\n",
    "\n",
    "    return _make_stream(tr_stream, batch_size), _make_stream(val_stream, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntrain 50000, nval 10000\n"
     ]
    }
   ],
   "source": [
    "data1, data2 = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'features', u'targets']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "data0 = h5py.File(PATH,'r')\n",
    "data0.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurearray = np.array(data0['features'][:])\n",
    "featurearray.shape\n",
    "firstimage = featurearray[1,:]\n",
    "firstimage.shape\n",
    "firstimage2 = firstimage.reshape(1, 3, 32, 32)\n",
    "firstimage2.shape\n",
    "firstimage3 = np.array(firstimage.reshape(3*32*32))\n",
    "firstimage3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "color_grid_vis(firstimage2, 1, 1, '/Users/wildflowerlyi/Desktop/testimage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadsimple(batch_size=128): #LEILAEDIT: took out downsampling, changed validation data to CIFAR test set, changed tr_data in line 53 to val_data\n",
    "    \n",
    "    tr_data = H5PYDataset(PATH, which_sets=('train',))\n",
    "    val_data = H5PYDataset(PATH, which_sets=('test',))\n",
    "\n",
    "    ntrain = tr_data.num_examples\n",
    "    nval = val_data.num_examples\n",
    "\n",
    "    print \"ntrain {}, nval {}\".format(ntrain, nval)\n",
    "\n",
    "    tr_scheme = ShuffledScheme(examples=ntrain, batch_size=batch_size)\n",
    "    tr_stream = DataStream(tr_data, iteration_scheme=tr_scheme)\n",
    "\n",
    "    # te_scheme = SequentialScheme(examples=ntest, batch_size=batch_size)\n",
    "    # te_stream = DataStream(te_data, iteration_scheme=te_scheme)\n",
    "\n",
    "    val_scheme = SequentialScheme(examples=nval, batch_size=batch_size)\n",
    "    val_stream = DataStream(val_data, iteration_scheme=val_scheme)\n",
    "\n",
    "    return tr_stream, val_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntrain 50000, nval 10000\n"
     ]
    }
   ],
   "source": [
    "datasimple1, datasimple2 = loadsimple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
