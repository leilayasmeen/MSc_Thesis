{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "from imageio import imsave\n",
    "\n",
    "import keras\n",
    "\n",
    "import time\n",
    "import functools\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATASET = 'cifar10' # mnist_256\n",
    "SETTINGS = '32px_cifar' # mnist_256, 32px_small, 32px_big, 64px_small, 64px_big\n",
    "\n",
    "OUT_DIR = '/Users/wildflowerlyi/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "N_CHANNELS = 3\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "NUM_CLASSES = 10\n",
    "(x_train_set, y_train_set), (x_test_set, y_test_set) = cifar10.load_data()\n",
    "   \n",
    "x_train_set = x_train_set.transpose(0,3,1,2)\n",
    "x_test_set = x_test_set.transpose(0,3,1,2)\n",
    "    \n",
    "seed = 333\n",
    "x_train_set, x_dev_set, y_train_set, y_dev_set = train_test_split(x_train_set, y_train_set, test_size=0.1, random_state=seed)\n",
    "\n",
    "from keras.utils import np_utils           \n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate numeric images into plots\n",
    "def color_grid_vis(X, nh, nw, save_path):\n",
    "  # from github.com/Newmu\n",
    "  X = X.transpose(0,2,3,1)\n",
    "  h, w = X[0].shape[:2]\n",
    "  img = np.zeros((h*nh, w*nw, 3))\n",
    "  for n, x in enumerate(X):\n",
    "    j = n/nw\n",
    "    i = n%nw\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x\n",
    "    imsave(OUT_DIR + '/' + save_path, img)            \n",
    "                \n",
    "numsamples = 1250\n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_2', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_2', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_3', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_3', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_4', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_4', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_5', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_5', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_6', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_6', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_7', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_7', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_8', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_8', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 1250\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 4)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_9', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_9', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline.npy')\n",
    "print(x1.shape)\n",
    "y1 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline.npy')\n",
    "print(y1.shape)\n",
    "x2 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_2.npy')\n",
    "print(x2.shape)\n",
    "y2 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_2.npy')\n",
    "print(y2.shape)\n",
    "x3 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_3.npy')\n",
    "print(x3.shape)\n",
    "y3 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_3.npy')\n",
    "print(y3.shape)\n",
    "x4 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_4.npy')\n",
    "print(x4.shape)\n",
    "y4 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_4.npy')\n",
    "print(y4.shape)\n",
    "x5 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_5.npy')\n",
    "print(x5.shape)\n",
    "y5 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_5.npy')\n",
    "print(y5.shape)\n",
    "x6 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_6.npy')\n",
    "print(x6.shape)\n",
    "y6 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_6.npy')\n",
    "print(y6.shape)\n",
    "x7 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_7.npy')\n",
    "print(x7.shape)\n",
    "y7 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_7.npy')\n",
    "print(y7.shape)\n",
    "x8 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_8.npy')\n",
    "print(x8.shape)\n",
    "y8 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_8.npy')\n",
    "print(y8.shape)\n",
    "x9 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_beta_baseline_9.npy')\n",
    "print(x9.shape)\n",
    "y9 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_beta_baseline_9.npy')\n",
    "print(y9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mixup_beta_baseline = np.concatenate((x1,x2,x3,x4,x5,x6,x7,x8,x9), axis=0)\n",
    "y_mixup_beta_baseline = np.concatenate((y1,y2,y3,y4,y5,y6,y7,y8,y9), axis=0)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_beta_baseline_full', x_mixup_beta_baseline) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_beta_baseline_full', y_mixup_beta_baseline) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
