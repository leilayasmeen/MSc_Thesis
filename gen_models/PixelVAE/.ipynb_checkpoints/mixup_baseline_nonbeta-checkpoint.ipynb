{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "from imageio import imsave\n",
    "\n",
    "import keras\n",
    "\n",
    "import time\n",
    "import functools\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATASET = 'cifar10' # mnist_256\n",
    "SETTINGS = '32px_cifar' # mnist_256, 32px_small, 32px_big, 64px_small, 64px_big\n",
    "\n",
    "OUT_DIR = '/Users/wildflowerlyi/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "N_CHANNELS = 3\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "NUM_CLASSES = 10\n",
    "(x_train_set, y_train_set), (x_test_set, y_test_set) = cifar10.load_data()\n",
    "   \n",
    "x_train_set = x_train_set.transpose(0,3,1,2)\n",
    "x_test_set = x_test_set.transpose(0,3,1,2)\n",
    "    \n",
    "seed = 333\n",
    "x_train_set, x_dev_set, y_train_set, y_dev_set = train_test_split(x_train_set, y_train_set, test_size=0.1, random_state=seed)\n",
    "\n",
    "from keras.utils import np_utils           \n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate numeric images into plots\n",
    "def color_grid_vis(X, nh, nw, save_path):\n",
    "  # from github.com/Newmu\n",
    "  X = X.transpose(0,2,3,1)\n",
    "  h, w = X[0].shape[:2]\n",
    "  img = np.zeros((h*nh, w*nw, 3))\n",
    "  for n, x in enumerate(X):\n",
    "    j = n/nw\n",
    "    i = n%nw\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x\n",
    "    imsave(OUT_DIR + '/' + save_path, img)            \n",
    "                \n",
    "numsamples = 15\n",
    "pvals = np.linspace(0.2, 0.8, num=4)\n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_2', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_2', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_3', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_3', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_4', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_4', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_5', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_5', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_6', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_6', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_7', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_7', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_8', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_8', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 5\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_9', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_9', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_10', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_10', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_11', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_11', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_12', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_12', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_13', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_13', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_14', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_14', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_15', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_15', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_16', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_16', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 15\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_17', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_17', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsamples = 5\n",
    "\n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    for class1 in range(NUM_CLASSES-1):\n",
    "        idx1 = np.asarray(np.where(np.equal(class1, y_train_set))[0])\n",
    "        x_trainsubset1 = x_train_set_array[idx1,:]\n",
    "        y_trainsubset1 = y_train_set_array[idx1,:]\n",
    "        x_trainsubset1 = x_trainsubset1.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "        y_trainsubset1 = y_trainsubset1.reshape(-1, 1)\n",
    "        \n",
    "        for class2 in range(class1+1, NUM_CLASSES):\n",
    "            idx2 = np.asarray(np.where(np.equal(class2, y_train_set))[0])\n",
    "            x_trainsubset2 = x_train_set_array[idx2,:]\n",
    "            y_trainsubset2 = y_train_set_array[idx2,:]\n",
    "            x_trainsubset2 = x_trainsubset2.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            y_trainsubset2 = y_trainsubset2.reshape(-1, 1)\n",
    "                    \n",
    "            imageindex1 = random.sample(range(x_trainsubset1.shape[0]),1)\n",
    "            imageindex2 = random.sample(range(x_trainsubset2.shape[0]),1)\n",
    "                    \n",
    "            # Draw the corresponding images and labels from the training data\n",
    "            image1 = x_trainsubset1[imageindex1,:]\n",
    "            image2 = x_trainsubset2[imageindex2,:]  \n",
    "            label1 = y_trainsubset1[imageindex1,:]\n",
    "            label2 = y_trainsubset2[imageindex2,:]\n",
    "        \n",
    "            #pvals = np.random.beta(0.2, 0.2, 1)\n",
    "    \n",
    "            # Reshape\n",
    "            xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "            label1 = label1.reshape(1, 1)\n",
    "            label2 = label2.reshape(1, 1)\n",
    "                          \n",
    "            # Change labels to matrix form before performing interpolations\n",
    "            y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "            y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "            # Combine the arrays and labels\n",
    "            for p in pvals:\n",
    "                new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "                new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "                new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "                x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "                y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "                              \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_18', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_18', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 3, 32, 32)\n",
      "(3600, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(900, 3, 32, 32)\n",
      "(900, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "x1array = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline.npy')\n",
    "print(x1array.shape)\n",
    "y1array = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline.npy')\n",
    "print(y1array.shape)\n",
    "x2array = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_2.npy')\n",
    "print(x2array.shape)\n",
    "y2array = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_2.npy')\n",
    "print(y2array.shape)\n",
    "x3 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_3.npy')\n",
    "print(x3.shape)\n",
    "y3 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_3.npy')\n",
    "print(y3.shape)\n",
    "x4 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_4.npy')\n",
    "print(x4.shape)\n",
    "y4 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_4.npy')\n",
    "print(y4.shape)\n",
    "x5 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_5.npy')\n",
    "print(x5.shape)\n",
    "y5 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_5.npy')\n",
    "print(y5.shape)\n",
    "x6 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_6.npy')\n",
    "print(x6.shape)\n",
    "y6 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_6.npy')\n",
    "print(y6.shape)\n",
    "x7 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_7.npy')\n",
    "print(x7.shape)\n",
    "y7 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_7.npy')\n",
    "print(y7.shape)\n",
    "x8 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_8.npy')\n",
    "print(x8.shape)\n",
    "y8 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_8.npy')\n",
    "print(y8.shape)\n",
    "x9 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_9.npy')\n",
    "print(x9.shape)\n",
    "y9 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_9.npy')\n",
    "print(y9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(2700, 3, 32, 32)\n",
      "(2700, 1, 10)\n",
      "(900, 3, 32, 32)\n",
      "(900, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "x10 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_10.npy')\n",
    "print(x10.shape)\n",
    "y10 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_10.npy')\n",
    "print(y10.shape)\n",
    "x11 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_11.npy')\n",
    "print(x11.shape)\n",
    "y11 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_11.npy')\n",
    "print(y11.shape)\n",
    "x12 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_12.npy')\n",
    "print(x12.shape)\n",
    "y12 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_12.npy')\n",
    "print(y12.shape)\n",
    "x13 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_13.npy')\n",
    "print(x13.shape)\n",
    "y13 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_13.npy')\n",
    "print(y13.shape)\n",
    "x14 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_14.npy')\n",
    "print(x14.shape)\n",
    "y14 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_14.npy')\n",
    "print(y14.shape)\n",
    "x15 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_15.npy')\n",
    "print(x15.shape)\n",
    "y15 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_15.npy')\n",
    "print(y15.shape)\n",
    "x16 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_16.npy')\n",
    "print(x16.shape)\n",
    "y16 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_16.npy')\n",
    "print(y16.shape)\n",
    "x17 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_17.npy')\n",
    "print(x17.shape)\n",
    "y17 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_17.npy')\n",
    "print(y17.shape)\n",
    "x18 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_nonbeta_baseline_18.npy')\n",
    "print(x18.shape)\n",
    "y18 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_nonbeta_baseline_18.npy')\n",
    "print(y18.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 3, 32, 32)\n",
      "(45000, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "x_mixup_nonbeta_baseline = np.concatenate((x1array,x2array,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17), axis=0)\n",
    "y_mixup_nonbeta_baseline = np.concatenate((y1array,y2array,y3,y4,y5,y6,y7,y8,y9,y10,y11,y12,y13,y14,y15,y16,y17), axis=0)\n",
    "\n",
    "print(x_mixup_nonbeta_baseline.shape)\n",
    "print(y_mixup_nonbeta_baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_nonbeta_baseline_full', x_mixup_nonbeta_baseline) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_nonbeta_baseline_full', y_mixup_nonbeta_baseline) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
