{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import imageio\n",
    "from imageio import imwrite\n",
    "from scipy.misc import imsave, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflib as lib\n",
    "import tflib.sampling_loop\n",
    "import tflib.ops.kl_unit_gaussian\n",
    "import tflib.ops.kl_gaussian_gaussian\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.embedding\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "(x_train_set, y_train_set), (x_test_set, y_test_set) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = 3\n",
    "HEIGHT = 32\n",
    "WIDTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_set = x_train_set.transpose(0,3,1,2)\n",
    "x_test_set = x_test_set.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 333\n",
    "x_train_set, x_dev_set, y_train_set, y_dev_set = train_test_split(x_train_set, y_train_set, test_size=0.1, random_state=seed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3, 32, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_set_sub = x_train_set.reshape(-1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "y_train_set_sub = y_train_set.reshape(-1, 1)\n",
    "print(x_train_set_sub.shape[0])\n",
    "x_train_set_sub[1,:].reshape(1,N_CHANNELS, HEIGHT, WIDTH).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n",
      "(9,)\n",
      "(1, 9)\n"
     ]
    }
   ],
   "source": [
    "all_latents = np.array([44,21,14,13,2,53,11,23,99])\n",
    "lat = np.arange(9)\n",
    "print(all_latents.shape)\n",
    "print(lat.shape)\n",
    "all_latents = all_latents.reshape(-1,9)\n",
    "print(all_latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(x_train_set_sub.shape[0]):\n",
    "    latestlatents = np.arange(9)\n",
    "    latestlatents = latestlatents.reshape(-1, 9)\n",
    "    all_latents = np.concatenate((all_latents, latestlatents), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45001, 9)\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "#print(all_latents.shape)\n",
    "#all_latents_mean = np.mean(all_latents, axis=0)\n",
    "#all_latents_mean2 = np.mean(all_latents, axis=0)\n",
    "#print(all_latents_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classmeans = np.zeros((10, 9)).astype('float32') #NUM_CLASSES LATENT DIM 2\n",
    "for k in range(10): #NUM_CLASSES\n",
    "    idk = np.asarray(np.where(np.equal(y_train_set_sub,k))[0])\n",
    "    all_latents_groupk = all_latents[idk,:]\n",
    "    classmeans[k,:] = np.mean(all_latents_groupk, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = np.asarray(np.where(np.equal(y_train_set_sub,1))[0])\n",
    "idk\n",
    "idk2 = np.asarray(np.where(np.equal(y_train_set_sub,2))[0])\n",
    "idk2\n",
    "print(classmeans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classindices = np.array([[0,6],[3,8]])\n",
    "classindices[0,]\n",
    "classindices.shape[0]\n",
    "idx = np.zeros(classindices.shape[0])\n",
    "for classnums in xrange(classindices.shape[0]):\n",
    "    idx[classnums] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "all_latents = np.zeros((3,8)).astype('float32')\n",
    "print(all_latents)\n",
    "all_latents = np.delete(all_latents, -1, axis=1)\n",
    "print(all_latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [1 3]\n",
      " [1 4]\n",
      " [1 5]\n",
      " [2 3]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [3 4]\n",
      " [3 5]\n",
      " [4 5]]\n",
      "10\n",
      "[1 3]\n",
      "[1 4]\n",
      "4\n",
      "[1 3]\n",
      "[1.  3.5]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "pairlist = np.array([1,2,3,4,5])\n",
    "listcombos = list(itertools.combinations(pairlist,2))\n",
    "#print(listcombos)\n",
    "arraycombos = np.array(list(itertools.combinations(pairlist,2)))\n",
    "print(arraycombos)\n",
    "print(arraycombos.shape[0])\n",
    "\n",
    "meanvec = np.mean([arraycombos[1],arraycombos[2]], axis=0)\n",
    "meow = np.zeros(1)\n",
    "print(meanvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Test how to index things\n",
    "y_train = [4, 0, 1, 2, 3, 4]\n",
    "idx = np.where(np.equal(y_train[0],y_train))\n",
    "print(idx[0])\n",
    "idx1 = np.where(np.equal(y_train,y_train[0]))\n",
    "print(idx1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How data is loaded into PixelVAE\n",
    "data = urllib.urlretrieve('http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz', 'mnist_test.gz')[0]\n",
    "\n",
    "with gzip.open(data, 'rb') as f:\n",
    "    train_data, dev_data, test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[0][1]) # pixels are in the range 0-1\n",
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_reshape(data):\n",
    "    \n",
    "    images, targets = data\n",
    "    images = images.astype('float32')\n",
    "    images = images.reshape(-1, 784)\n",
    "    images2 = (images*(256-1e-8)).astype('int32')\n",
    "    \n",
    "    targets = targets.astype('float32')\n",
    "\n",
    "    return(np.copy(images2), np.copy(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mnist_reshape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(train_data[1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[0][index[0]]) # pixels are now integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_samples = train_data[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_samples = train_data[1][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target = (np.mean(label_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images as uint8 arrays\n",
    "image_samples_int8  = image_samples.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_new = image_samples, label_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = image_samples[1], label_samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(samples_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(samples_new[0][0]) # before converting to uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(image_samples_int8[0]) # after converting to uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in png file and target as arrays\n",
    "testimage = imread('/Users/wildflowerlyi/Desktop/Github/reconstructions_mnist/original_0.png')\n",
    "reconimage = imread('/Users/wildflowerlyi/Desktop/Github/reconstructions_mnist/reconstruction_0.png')\n",
    "print(testimage.shape)\n",
    "print(testimage.dtype.name)\n",
    "print(reconimage.dtype.name)\n",
    "imwrite('/Users/wildflowerlyi/Desktop/test.png',testimage)\n",
    "testimage2 = np.load('/Users/wildflowerlyi/Desktop/Github/reconstructions_mnist/x_augmentation_array.npy')\n",
    "print(testimage2.shape)\n",
    "print(testimage2.dtype.name)\n",
    "print(testimage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = np.zeros([1,1,28,28], dtype='uint8')\n",
    "print(hi.dtype.name)\n",
    "hi2 = testimage2.astype(np.uint8)\n",
    "print(hi2.dtype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array([1, 0.4, 0.9])\n",
    "e2 = e.astype(np.uint8)\n",
    "print(e2)\n",
    "import keras\n",
    "e3 = keras.utils.to_categorical(e, num_classes=3)\n",
    "print(e3)\n",
    "print(e3 + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_grid_vis(X, nh, nw, save_path):\n",
    "    # from github.com/Newmu\n",
    "    X = X.transpose(0,2,3,1)\n",
    "    h, w = X[0].shape[:2]\n",
    "    img = np.zeros((h*nh, w*nw, 3))\n",
    "    for n, x in enumerate(X):\n",
    "        j = n/nw\n",
    "        i = n%nw\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = x\n",
    "    imwrite(save_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "import keras\n",
    "from keras.datasets import mnist, cifar10\n",
    "import imageio\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_traincifar, y_traincifar), (x_testcifar, y_testcifar) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(x_traincifar.shape)\n",
    "x_traincifar_new = x_traincifar.transpose(0,3,1,2)\n",
    "print(x_traincifar_new.shape)\n",
    "x_traincifar_new = x_traincifar.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xtrain = x_train.reshape(-1, 1, 28, 28)\n",
    "new_xtrain.shape\n",
    "new_ytrain = y_train.reshape(-1, 1)\n",
    "new_ytrain.shape\n",
    "new_xtrain.shape\n",
    "new_xtrain[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how to index things\n",
    "idx = np.where(np.equal(4,new_ytrain))\n",
    "print(idx[0])\n",
    "new_ytrain = np.array(new_ytrain)\n",
    "new_xtrain = np.array(new_xtrain)\n",
    "new_xtrain[idx[0]].shape\n",
    "x2 = new_xtrain[idx[0]][1].reshape(-1, 1, 28, 28)\n",
    "x2.shape\n",
    "new_xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a generated image and its corresponding target as a tuple\n",
    "outfile = TemporaryFile()\n",
    "#np.savez(outfile,image = testimage, label = testtarget)\n",
    "np.save(outfile, image = testimage)\n",
    "np.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile.seek(0)\n",
    "npzfile = np.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image\n",
    "# If MNIST\n",
    "newimage = sample1[0].reshape(-1, 28, 28)\n",
    "# If CIFAR\n",
    "#newimage = sample1[0].reshape(-1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image and target to dataset\n",
    "x_train_aug = np.append(x_train, newimage2, axis=0)\n",
    "y_train_aug = np.append(y_train, sample1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/wildflowerlyi/Desktop/test', x_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_augmentations_arrays = np.load('/Users/wildflowerlyi/Desktop/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING AUGMENTATIONS: FINAL\n",
    "# (0) Initialize image array\n",
    "# (1) Produce image array\n",
    "# (2) Add image array to those before\n",
    "# (3) Save final array at end of for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert this at line 798\n",
    "x_augmentations_array = []\n",
    "\n",
    "# Insert this line under the sample generation loop in line 823\n",
    "print \"Appending image array to those previously generated\"\n",
    "    x_augmentations_array = np.append(x_augmentations_array, samples, axis=0)\n",
    "\n",
    "# Insert this line after all images have been added, after line 834 (make sure not indented)\n",
    "np.save('x_augmentations_array', x_augmentations_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING IN AUGMENTATIONS TO TRAIN NEURAL NETWORKS: FINAL\n",
    "# (1) Read in x and y augmentations as new_x and new_y\n",
    "# (2) Transpose new_x = new_x.transpose(0, 3, 1, 2)\n",
    "#     x_augmented = np.append(x_train, new_x, axis=0)\n",
    "#     y_augmented = np.append(y_train, new_y, axis=0)\n",
    "\n",
    "# Add the below text at the beginning of train_cifar10 files in each directory. Make sure the augmented files are \n",
    "# in each of the folders resnet_cifar, resnet_wide, resnet_densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "import keras\n",
    "from keras.datasets import mnist, cifar10\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_traincifar, y_traincifar), (x_testcifar, y_testcifar) = cifar10.load_data()\n",
    "\n",
    "# Load augmented arrays\n",
    "new_x = np.load('/Users/wildflowerlyi/Desktop/Github/NN_calibration/scripts/resnet_cifar/x_augmentation_array.npy')\n",
    "new_y = np.load('/Users/wildflowerlyi/Desktop/Github/NN_calibration/scripts/resnet_cifar/y_augmentation_array.npy')\n",
    "\n",
    "# Reshape from (H,W,CH) to (CH,H,W)\n",
    "# new_x = np.transpose(new_x, (2, 1, 0)) # Only for CIFAR\n",
    "\n",
    "# Add images and targets to original dataset\n",
    "x_train_aug = np.append(x_train, new_x, axis=0)\n",
    "y_train_aug = np.append(y_train, new_y, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
