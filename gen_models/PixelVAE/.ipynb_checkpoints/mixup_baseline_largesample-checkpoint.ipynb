{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "from imageio import imsave\n",
    "\n",
    "import keras\n",
    "\n",
    "import time\n",
    "import functools\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATASET = 'cifar10' # mnist_256\n",
    "SETTINGS = '32px_cifar' # mnist_256, 32px_small, 32px_big, 64px_small, 64px_big\n",
    "\n",
    "OUT_DIR = '/Users/wildflowerlyi/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "N_CHANNELS = 3\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "NUM_CLASSES = 10\n",
    "(x_train_set, y_train_set), (x_test_set, y_test_set) = cifar10.load_data()\n",
    "   \n",
    "x_train_set = x_train_set.transpose(0,3,1,2)\n",
    "x_test_set = x_test_set.transpose(0,3,1,2)\n",
    "    \n",
    "seed = 333\n",
    "x_train_set, x_dev_set, y_train_set, y_dev_set = train_test_split(x_train_set, y_train_set, test_size=0.1, random_state=seed)\n",
    "\n",
    "from keras.utils import np_utils           \n",
    "x_augmentation_set = np.zeros((1, N_CHANNELS, HEIGHT, WIDTH)) #LEILEDIT: to enable .npy image saving\n",
    "y_augmentation_set = np.zeros((1, 1, NUM_CLASSES)) #LEILEDIT: to enable .npy image saving. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5a20e95e55de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mnew_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mx_augmentation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_augmentation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_xarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#LEILAEDIT for .npy saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0my_augmentation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_augmentation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#LEILAEDIT for .npy saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "numsamples = 5000\n",
    "            \n",
    "x_train_set_array = np.array(x_train_set)\n",
    "y_train_set_array = np.array(y_train_set)  \n",
    "\n",
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline', y_augmentation_array) #LEILAEDIT for .npy saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_2', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_2', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_3', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_3', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_4', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_4', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_5', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_5', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_6', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_6', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_7', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_7', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_8', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_8', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagenum in range(numsamples):\n",
    "    pvals = np.random.beta(0.2, 0.2, 1)\n",
    "                    \n",
    "    imageindices = random.sample(range(x_train_set.shape[0]),2)\n",
    "    imageindex1 = imageindices[0]\n",
    "    imageindex2 = imageindices[1]\n",
    "                    \n",
    "    # Draw the corresponding images and labels from the training data\n",
    "    image1 = x_train_set[imageindex1,:]\n",
    "    image2 = x_train_set[imageindex2,:]  \n",
    "    label1 = y_train_set[imageindex1,:]\n",
    "    label2 = y_train_set[imageindex2,:]\n",
    "                \n",
    "    # Reshape\n",
    "    xarray1 = image1.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    xarray2 = image2.reshape(1, N_CHANNELS, HEIGHT, WIDTH)\n",
    "    label1 = label1.reshape(1, 1)\n",
    "    label2 = label2.reshape(1, 1)\n",
    "                    \n",
    "    # Save the original images\n",
    "    #print \"Saving original samples\"\n",
    "    #color_grid_vis(\n",
    "    #    xarray1,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_1_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )\n",
    "    #color_grid_vis(\n",
    "    #    xarray2,\n",
    "    #    1,\n",
    "    #    1,\n",
    "    #    'original_2_classes{}and{}_num{}.png'.format(label1,label2,imagenum)\n",
    "    #    )      \n",
    "               \n",
    "    # Change labels to matrix form before performing interpolations\n",
    "    y1 = np_utils.to_categorical(label1, NUM_CLASSES) \n",
    "    y2 = np_utils.to_categorical(label2, NUM_CLASSES) \n",
    "                     \n",
    "    # Combine the arrays and labels\n",
    "    for p in pvals:\n",
    "        new_xarray = np.multiply(p,xarray1) + np.multiply((1-p),xarray2)\n",
    "        new_label = np.multiply(p,y1) + np.multiply((1-p),y2)\n",
    "        new_label = new_label.reshape(1,1,NUM_CLASSES)\n",
    "\n",
    "        x_augmentation_set = np.concatenate((x_augmentation_set, new_xarray), axis=0)#LEILAEDIT for .npy saving\n",
    "        y_augmentation_set = np.concatenate((y_augmentation_set, new_label), axis=0)#LEILAEDIT for .npy saving\n",
    "               \n",
    "x_augmentation_array = np.delete(x_augmentation_set, (0), axis=0)\n",
    "y_augmentation_array = np.delete(y_augmentation_set, (0), axis=0)\n",
    "            \n",
    "x_augmentation_array = x_augmentation_array.astype(np.uint8)\n",
    "\n",
    "np.save(OUT_DIR + '/' + 'x_augmentation_array_mixup_largesample_baseline_9', x_augmentation_array) #LEILAEDIT for .npy saving\n",
    "np.save(OUT_DIR + '/' + 'y_augmentation_array_mixup_largesample_baseline_9', y_augmentation_array) #LEILAEDIT for .npy saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline.npy')\n",
    "print(x1.shape)\n",
    "y1 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline.npy')\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_2.npy')\n",
    "print(x2.shape)\n",
    "y2 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_2.npy')\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_3.npy')\n",
    "print(x3.shape)\n",
    "y3 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_3.npy')\n",
    "print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_4.npy')\n",
    "print(x4.shape)\n",
    "y4 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_4.npy')\n",
    "print(y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_5.npy')\n",
    "print(x5.shape)\n",
    "y5 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_5.npy')\n",
    "print(y5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x6 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_6.npy')\n",
    "print(x6.shape)\n",
    "y6 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_6.npy')\n",
    "print(y6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x7 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_7.npy')\n",
    "print(x7.shape)\n",
    "y7 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_7.npy')\n",
    "print(y7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x8 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_8.npy')\n",
    "print(x8.shape)\n",
    "y8 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_8.npy')\n",
    "print(y8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x9 = np.load('/Users/wildflowerlyi/Desktop/x_augmentation_array_mixup_largesample_baseline_9.npy')\n",
    "print(x9.shape)\n",
    "y9 = np.load('/Users/wildflowerlyi/Desktop/y_augmentation_array_mixup_largesample_baseline_9.npy')\n",
    "print(y9.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
