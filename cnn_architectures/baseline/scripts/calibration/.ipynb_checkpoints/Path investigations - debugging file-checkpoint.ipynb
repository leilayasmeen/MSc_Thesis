{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating calibration methods on convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from cal_methods import TemperatureScaling, evaluate, softmax\n",
    "import pickle\n",
    "from sklearn.isotonic import IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/Users/wildflowerlyi/Desktop/Github/NN_calibration/scripts'\n",
    "myfiles = ('resnet_cifar/probs_resnet110_c10_logits.p', 'resnet_cifar/probs_resnet110_c100_logits.p'\n",
    "        #, 'resnet_wide/probs_resnet_wide32_c10_logits.p','resnet_wide/probs_resnet_wide32_c100_logits.p'\n",
    "        #, 'resnet_densenet/probs_densenet40_c10_logits.p','resnet_densenet/probs_densenet40_c100_logits.p'\n",
    "        #,'resnet_wide/probs_resnet_wide32_c10clip_logits.p','resnet_wide/probs_resnet_wide32_c100clip_logits.p'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/wildflowerlyi/Desktop/Github/NN_calibration/scripts'\n",
    "files = ('resnet_cifar/probs_resnet110_c10_logits.p'\n",
    "        , 'resnet_wide/probs_resnet_wide32_c10_logits.p'\n",
    "        #, 'resnet_densenet/probs_densenet40_c10_logits.p'\n",
    "        #,'resnet_wide/probs_resnet_wide32_c10clip_logits.p'\n",
    "        #,'resnet_sd/probs_resnet110_SD_c10clip_logits.p'\n",
    "        #,'resnet_cifar/probs_resnet110_c100_logits.p'\n",
    "        #,'resnet_wide/probs_resnet_wide32_c100_logits.p'\n",
    "        #,'resnet_densenet/probs_densenet40_c100_logits.p'\n",
    "        #,'resnet_wide/probs_resnet_wide32_c100clip_logits.p'    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myfilepath = join(mypath, myfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myfilepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file with pickled variables\n",
    "def unpickle_probs(filepath, verbose = 0):\n",
    "    with open(filepath, 'rb') as f:  \n",
    "        (y_probs_val, y_val), (y_probs_test, y_test) = pickle.load(f)  # unpickle the content\n",
    "        \n",
    "    if verbose:    \n",
    "        print(\"y_probs_val:\", y_probs_val.shape)  # (5000, 10); Validation set probabilities of predictions\n",
    "        print(\"y_true_val:\", y_val.shape)  # (5000, 1); Validation set true labels\n",
    "        print(\"y_probs_test:\", y_probs_test.shape)  # (10000, 10); Test set probabilities\n",
    "        print(\"y_true_test:\", y_test.shape)  # (10000, 1); Test set true labels\n",
    "        \n",
    "    return ((y_probs_val, y_val), (y_probs_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(y_probs_val, y_val), (y_probs_test, y_test) = unpickle_probs(myfilepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    #print(f)\n",
    "    #print(files[:][:])\n",
    "    print(join(PATH,f))\n",
    "    #(logits_val, y_val), (logits_test, y_test) = unpickle_probs(join(mypath,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(files):\n",
    "    #print(f)\n",
    "    #print(files[:][:])\n",
    "    print i, f\n",
    "    print(join(PATH,f[:0]))\n",
    "    #(logits_val, y_val), (logits_test, y_test) = unpickle_probs(join(PATH,f[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_results(fn, path, files, m_kwargs = {}, approach = \"all\"):\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Name\", \"Error\", \"ECE\", \"MCE\", \"Loss\"])\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        name = \"_\".join(f.split(\"_\")[1:-1])\n",
    "        print(name)\n",
    "        filepath = join(path,f[0:])\n",
    "        (logits_val, y_val), (logits_test, y_test) = unpickle_probs(filepath)\n",
    "        \n",
    "        if approach == \"all\":            \n",
    "\n",
    "            y_val = y_val.flatten()\n",
    "\n",
    "            model = fn(**m_kwargs)\n",
    "\n",
    "            model.fit(logits_val, y_val)\n",
    "\n",
    "            probs_test = model.predict(logits_test)\n",
    "            \n",
    "            # Replace NaN with epsilon close to zero, as it should be close to zero \n",
    "            idx_nan = np.where(np.isnan(probs_test))\n",
    "            probs_test[idx_nan] = 0.00000000000000000000000000000000000000001\n",
    "            \n",
    "            error, ece, mce, loss = evaluate(softmax(logits_test), y_test, verbose=True)  # Test before scaling\n",
    "            error2, ece2, mce2, loss2 = evaluate(probs_test, y_test, verbose=False)\n",
    "            \n",
    "        else:  # 1-vs-k models\n",
    "            probs_val = softmax(logits_val)  # Softmax logits\n",
    "            probs_test = softmax(logits_test)\n",
    "            K = probs_test.shape[1]\n",
    "            \n",
    "            # Replace NaN with epsilon close to zero, as it should be close to zero \n",
    "            idx_nan = np.where(np.isnan(probs_test))\n",
    "            probs_test[idx_nan] = 0.00000000000000000000000000000000000000001\n",
    "\n",
    "            idx_nan = np.where(np.isnan(probs_val))\n",
    "            probs_val[idx_nan] = 0.00000000000000000000000000000000000000001\n",
    "            \n",
    "            # Go through all the classes\n",
    "            for k in range(K):\n",
    "                # Prep class labels (1 fixed true class, 0 other classes)\n",
    "                y_cal = np.array(y_val == k, dtype=\"int\")[:, 0]\n",
    "\n",
    "                # Train model\n",
    "                model = fn(**m_kwargs)\n",
    "                model.fit(probs_val[:, k], y_cal) # Get only one column with probs for given class \"k\"\n",
    "\n",
    "                probs_test[:, k] = model.predict(probs_test[:, k])\n",
    "\n",
    "            # Get results for test set\n",
    "            error, ece, mce, loss = evaluate(softmax(logits_test), y_test, verbose=True, normalize=False)\n",
    "            error2, ece2, mce2, loss2 = evaluate(probs_test, y_test, verbose=False, normalize=True)\n",
    "                  \n",
    "        df.loc[i*2] = [name, error, ece, mce, loss]\n",
    "        df.loc[i*2+1] = [(name + \"_calib\"), error2, ece2, mce2, loss2]\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_iso = cal_results(IsotonicRegression, mypath, myfiles, {'y_min':0, 'y_max':1}, approach = \"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar/probs_resnet110_c10\n",
      "('Accuracy:', 93.390000000000001)\n",
      "('Error:', 6.6099999999999994)\n",
      "('ECE:', 0.048270407003164296)\n",
      "('MCE:', 0.379260828194109)\n",
      "('Loss:', 0.38292819397349553)\n",
      "wide/probs_resnet_wide32_c10\n",
      "('Accuracy:', 93.799999999999997)\n",
      "('Error:', 6.2000000000000028)\n",
      "('ECE:', 0.047311796060204525)\n",
      "('MCE:', 0.3678059713045756)\n",
      "('Loss:', 0.37100536326453859)\n"
     ]
    }
   ],
   "source": [
    "df_iso = cal_results(IsotonicRegression, PATH, files, {'y_min':0, 'y_max':1}, approach = \"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
